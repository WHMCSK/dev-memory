# LLM QA

一、基座模型预训练的数据量和模型参数量的关系

数据量：模型参数量，DeepMind提出1:1.75，OpenAI提出的是1:20

二、预训练的语料从何而来

1. 找开源数据集
2. 通过爬虫在网上爬取，然后自己洗数据

三、做预训练需要什么样的硬件配置

1. 没有2块A100起基本上做不了
2. 比较大规模的预训练，至少需要32张A100，或64张A100
3. 单卡只能用来训练1B参数规模的模型

四、现在做大模型预训练，语料一般多大

1. 最早大家都是用100B、200B，GPT3也是用的200B语料
2. 最近大家都用更大的，比如Lamma用的2T的语料，这种用64卡、128卡，怎么也得训一个月

五、我们行业的数据没有被包含到开源模型中，如何做出一个我们行业的模型？

这里要说Continues Pretraining（二次做训练）或者Pretraining。二次训练也就是做Instruction tuning，如果Instruct足够多，就不用碰预训练，只需要做Instruction tuneing就可以了。因为开源的这些预训练模型已经具备了足够的知识，再进行Instruction tuneing，其实是为了让大模型把这些知识更好的表达出来，也就是说人话。如果Instruction不够多，或者不够好，可以把Instruction放到预训练里面做

六、指令微调大概要用多少数据

1. Aplaca大概5千条
2. Vicuna用了几万条
3. 最少得有几千条，如果制作分类、抽取大概8千条以上就有非常好的效果

七、指令微调的数据有必要清晰吗？如何清洗？

1. 非常重要，SFT的数据质量是非常重要的一个指标，你可能需要的训练数据并不需要特别多，但是一定要足够的干净。
2. SFT数据如何清洗呢？一般都是人看、或者从ChatGPT套数据。SFT数据现在都是人写的，除了人写，就是ChatGpt去套。

八、做SFT训练大概需要什么样的GPU资源？

1. 一般用4卡到8卡比较合理，也是相对Basic的门槛
2. 一张两张卡也能把模型放进去，但是要多少时间就不确定了

九、领域知识是在继续预训练阶段灌入，还是在SFT阶段去灌入？

这取决于数据是Instruction的形式还是无监督文本的形式，如果是“无监督文本的形式”，那就还是用继续预训练去做

十、SFT的时候是对整个模型的权重进行微调吗，还是其中几层？

这种首先了解一下Lora，Lora是对每个层后面加层，或者说加适配器，原来的模型参数是Freeze的，没有对原来的模型进行调整。具体是做微调还是做全调，看算力，如果算力足够就两种都做，看那种结果更好，如果算力不够就用Lora就可以了。通过一般经验，全量微调比Lora微调效果会更好一些。不过在做全调的时候注意不能调太多的apok，不然模型以前有的一些能力也许会忘掉了。

十一、SFT的训练代码也是做文字接龙吗？与预训练代码有什么区别吗？

本质上来讲没有区别，都是做Next Token的Prediction。
Instruction tuning stage

