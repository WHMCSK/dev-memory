# 大模型训练方法

## 1. LoRA

LoRA(Low Rank Adaptation of Large Language Models)大语言模型的低秩自适应

![](./assets/LoRA-01.jpg)

LoRA的基本原理是：冻结预训练好的模型权重参数，额外增加一个旁路网络，旁路网络里，有一个降维矩阵A、一个降维矩阵B，用变量R来控制下降维度R越小整体参数量就会越小。拿本地知识只训练这个旁路网络，这样不仅微调的成本显著下降，还能获得和全模型微调类似的效果哦。尽管LoRA的参数量相对全模型参数已经小了很多，但即便是消费级硬件，没几块4090还是很难玩得起来。有没有更轻量级的方法呢？当然有。最近比较活跃的开源项目LlamaIndex和LangChain就是更轻量级的方法。

LoRA的旁路网络的输入是预训练模型的输出，输出是预训练模型的中间层的输出。旁路网络的作用是学习到预训练模型的长-范围的语义信息。

LoRA的主要思想是通过训练一个小型的语言模型来学习大型的语言模型的表示，从而达到学习大型语言模型的目的。具体来说，LoRA的训练过程如下：

1. 首先，训练一个小型的语言模型，如GPT-2。
2. 然后，使用大型的语料库对小型模型进行微调，使其能够更好地适应大型语料库。
3. 最后，使用小型模型的输出作为输入，训练一个新的大型模型，如BERT。

LoRA的优点是训练速度快，适用于大型语料库，且能够学习到大型模型的长-范围的语义信息。

## 2. 蒸馏

蒸馏(Distillation)是一种模型压缩技术，通过将一个大的模型压缩到一个小型的模型，来达到模型压缩的目的。蒸馏的主要思想是通过让一个大的模型学习到一个小型的模型的输出，从而达到模型压缩的目的。具体来说，蒸馏的训练过程如下：

1. 首先，训练一个大的模型，如BERT。
2. 然后，使用一个小型的模型，如GPT-2，来学习大型模型的输出。
3. 最后，使用蒸馏损失函数，使得小型模型的输出和大型模型的输出尽可能相似。


蒸馏的优点是能够有效地压缩模型大小，且能够学习到大型模型的长-范围的语义信息。